{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Discriminator Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from configs.Metric import Metric\n",
    "from configs.SimulatedData import Proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= Proposed()\n",
    "\n",
    "SEQUENCE_LENGTH = config.sequence_lenght_in_sample\n",
    "GRANUARITY = config.granularity\n",
    "OVERLAP = config.overlap\n",
    "BS = config.batch_size\n",
    "EPOCHS = 50 # config.epochs\n",
    "NUM_SEQUENCE_TO_GENERATE = config.met_params.sequence_to_generate\n",
    "\n",
    "SIMULATED_DATA_PATH = \"data/simulated_dataset/01 - Source Domain.h5\"\n",
    "SIMULATED_TARGET_DOMAIN = \"data/simulated_dataset/output_noise/0.75.h5\"\n",
    "\n",
    "N_SAMPLE_WIENER = SEQUENCE_LENGTH//4\n",
    "FEAT_WIENER = 2\n",
    "NOISE_DIM= (N_SAMPLE_WIENER, FEAT_WIENER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_to_tensorflow_sequences(df:pd.DataFrame, sequence_lenght_in_sample, granularity, shift_between_sequences, batch_size, shuffle=True):\n",
    "    sequence_lenght = int(sequence_lenght_in_sample*granularity)\n",
    "\n",
    "    dset = tf.data.Dataset.from_tensor_slices(df.values)\n",
    "    dset = dset.window(sequence_lenght , shift=shift_between_sequences, stride=granularity).flat_map(lambda x: x.batch(sequence_lenght_in_sample, drop_remainder=True))\n",
    "\n",
    "    if shuffle:\n",
    "        dset= dset.shuffle(256)\n",
    "\n",
    "    dset = dset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # dset = dset.cache().prefetch(10)\n",
    "\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d1 = pd.read_hdf(SIMULATED_DATA_PATH)\n",
    "shape = df_d1.shape[0]\n",
    "df_d1 = df_d1.iloc[:int(shape/2)]\n",
    "\n",
    "df_d2 = pd.read_hdf(SIMULATED_TARGET_DOMAIN)\n",
    "shape = df_d2.shape[0]\n",
    "df_d2 = df_d2.iloc[:int(shape/2)]\n",
    "\n",
    "dset_style1 = convert_dataframe_to_tensorflow_sequences(\n",
    "    df_d1, \n",
    "    SEQUENCE_LENGTH, \n",
    "    GRANUARITY, \n",
    "    int(OVERLAP* SEQUENCE_LENGTH),\n",
    "    BS,\n",
    "    shuffle=False\n",
    ")\n",
    "dset_style1 = dset_style1.map(lambda batch: (batch, tf.zeros(BS, 1)), num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "dset_style2 = convert_dataframe_to_tensorflow_sequences(\n",
    "    df_d2, \n",
    "    SEQUENCE_LENGTH, \n",
    "    GRANUARITY, \n",
    "    int(OVERLAP* SEQUENCE_LENGTH),\n",
    "    BS,\n",
    "    shuffle=False\n",
    ")\n",
    "dset_style2 = dset_style2.map(lambda batch: (batch, tf.zeros(BS, 1) +1), num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "dset_style1= dset_style1.unbatch()\n",
    "dset_style2= dset_style2.unbatch()\n",
    "\n",
    "dset = tf.data.Dataset.sample_from_datasets([dset_style1, dset_style2])\n",
    "\n",
    "dset= dset.batch(BS, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = next(iter(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sequences from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_s1, _ = next(iter(dset_style1))\n",
    "seq_s2, _ = next(iter(dset_style2))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "ax = plt.subplot(211)\n",
    "ax.set_title('Style 1 Sequence.')\n",
    "plt.plot(seq_s1)\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "ax.set_title('Style 2 Sequence.')\n",
    "plt.plot(seq_s2)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AdaIN Layers for Time Series\n",
    "class AdaIN(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "\n",
    "    def get_mean_std(self, x, eps=1e-5):\n",
    "        _mean, _variance = tf.nn.moments(x, axes=[1], keepdims=True)\n",
    "        standard_dev = tf.sqrt(_variance+ eps)\n",
    "        return _mean, standard_dev\n",
    "\n",
    "    def call(self, content_input, style_input):\n",
    "        # print(content_input.shape, style_input.shape)\n",
    "        content_mean, content_std = self.get_mean_std(content_input)\n",
    "        style_mean, style_std = self.get_mean_std(style_input)\n",
    "        adain_res =style_std* (content_input - content_mean) / content_std+ style_mean\n",
    "        return adain_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder(n_sample_wiener:int, feat_wiener:int, style_vector_size:int, out_feat:int):\n",
    "    _content_input = tf.keras.Input((n_sample_wiener, feat_wiener), name=\"Content Time Series\")\n",
    "    _style_input = tf.keras.Input((style_vector_size, 1), name=\"Style Input\") \n",
    "    _style_input = tf.keras.layers.Flatten()(_style_input)\n",
    "\n",
    "    stage_1_style = tf.keras.layers.Dense(16, name='1')(_style_input)\n",
    "    stage_1_style = tf.keras.layers.Reshape((16, 1))(stage_1_style)\n",
    "\n",
    "    # stage_2_style = tf.keras.layers.Dense(32, name='2')(_style_input)\n",
    "    # stage_2_style = tf.keras.layers.Reshape((32, 1))(stage_2_style)\n",
    "\n",
    "\n",
    "    # mini content encoding.\n",
    "    _content_encoded = tf.keras.layers.Conv1D(128, 5, 1, padding='same', activation=\"relu\")(_content_input)\n",
    "    _content_encoded = tf.keras.layers.Conv1D(128, 5, 1, padding='same', activation=\"relu\")(_content_encoded)\n",
    "\n",
    "\n",
    "\n",
    "    x = AdaIN()(_content_encoded, stage_1_style)\n",
    "    x = tf.keras.layers.Conv1D(256, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    # x = AdaIN()(x, stage_1_style)\n",
    "    x = tf.keras.layers.Conv1D(256, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    # x = AdaIN()(x, stage_1_style)\n",
    "    x = tf.keras.layers.Conv1D(256, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv1DTranspose(128, 5, 2, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # x = AdaIN()(x, stage_2_style)\n",
    "    x = tf.keras.layers.Conv1D(512, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    # x = AdaIN()(x, stage_2_style)    \n",
    "    x = tf.keras.layers.Conv1D(512, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    # x = AdaIN()(x, stage_2_style)\n",
    "    x = tf.keras.layers.Conv1D(512, 5, 1, padding='same', activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv1DTranspose(out_feat, 5, 2, padding='same', activation=\"linear\")(x)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model([_content_input, _style_input], x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_multitask_discriminator(seq_length:int, n_feat:int, n_style_class:int):\n",
    "    _input = tf.keras.Input((seq_length, n_feat))\n",
    "    x = tf.keras.layers.Conv1D(64, 5, 2, padding='same')(_input)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv1D(64, 3, 1, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(128, 5, 2, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 3, 1, padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    flattened = tf.keras.layers.Flatten()(x)\n",
    "    _realness_output = tf.keras.layers.Dense(32, activation=\"relu\")(flattened)\n",
    "    # _realness_output = tf.keras.layers.Dense(32, activation=\"relu\")(_realness_output)\n",
    "    _realness_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(_realness_output)\n",
    "\n",
    "    _style_recognition_output = tf.keras.layers.Dense(n_style_class, activation='softmax')(flattened)\n",
    "\n",
    "    model = tf.keras.Model(_input, [_realness_output, _style_recognition_output])\n",
    "    early_discriminator = tf.keras.Model(_input, flattened)\n",
    "\n",
    "    return model, early_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_process(batch:int, n_sample_wiener:int, n_feat_wiener:int):\n",
    "    d_noise = tf.random.normal([batch, n_sample_wiener, n_feat_wiener])\n",
    "    wiener_noise = tf.math.cumsum(d_noise, axis=1)\n",
    "    return wiener_noise\n",
    "\n",
    "seed = wiener_process(NUM_SEQUENCE_TO_GENERATE, N_SAMPLE_WIENER, FEAT_WIENER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the generator works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_decoder(N_SAMPLE_WIENER, FEAT_WIENER, 1, df_d2.shape[1])\n",
    "discriminator, feature_projector= make_multitask_discriminator(SEQUENCE_LENGTH, df_d2.shape[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()\n",
    "tf.keras.utils.plot_model(generator, \"model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(discriminator, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sequences = generator([seed, tf.zeros(NUM_SEQUENCE_TO_GENERATE, 1)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(generated_sequences[0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "error_classif = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def style_classsification_loss(y_pred, y_true):\n",
    "    return error_classif(y_true, y_pred)\n",
    "\n",
    "def similarity_loss(extracted_features:np.ndarray):\n",
    "    anchor = extracted_features[0]\n",
    "    return tf.exp(-(tf.norm(extracted_features[1:]- anchor)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Correlation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_cov(a,v):\n",
    "    nan_mean_a = np.nanmean(a, axis=1).reshape((-1,1))\n",
    "    nan_mean_b = np.nanmean(v, axis=1).reshape((-1,1))\n",
    "    return np.nansum((a- nan_mean_a)* (v- nan_mean_b), axis=1)\n",
    "\n",
    "def mean_difference(a,v):\n",
    "    return np.nanmean(a) - np.nanmean(v)\n",
    "\n",
    "def optimized_windowed_cov(a, v, beta=Metric.mean_senssibility_factor):\n",
    "    if a.shape[1] > v.shape[1]:\n",
    "        _a, _v = v, a \n",
    "    else: \n",
    "        _a, _v = a, v\n",
    "\n",
    "    n = _a.shape[1]\n",
    "    corrs = []\n",
    "\n",
    "    for k in range(_v.shape[1] - _a.shape[1]):\n",
    "        __v = _v[:, k: n+k]\n",
    "        # Compute the covariance \n",
    "        augmented_cov = optimized_cov(_a,__v)+ beta* mean_difference(_a,__v)\n",
    "\n",
    "        corrs.append(augmented_cov)\n",
    "        \n",
    "    return np.array(corrs)\n",
    "\n",
    "def signature_on_batch(x:np.ndarray, ins:list, outs:list, sig_seq_len:int):\n",
    "    \"\"\"Compute the signature from a given batch of MTS sequences `x`\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): the batch\n",
    "        ins (list): input columns\n",
    "        outs (list): output label solumns\n",
    "        sig_seq_len (int): the desired signature length\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: the min, max, mean signature.\n",
    "    \"\"\"\n",
    "    sigs = []\n",
    "    shift = sig_seq_len//2\n",
    "    childrens = x[:, shift:-shift]\n",
    "\n",
    "    for _in in ins:\n",
    "        for _out in outs:\n",
    "            c1 = x[:, :, _in]\n",
    "            c2 = childrens[:, :, _out]\n",
    "            \n",
    "            sig = optimized_windowed_cov(c1, c2)\n",
    "\n",
    "            sigs.append(sig)\n",
    "\n",
    "    mins = np.min(sigs, axis=-1)\n",
    "    maxs = np.max(sigs, axis=-1)\n",
    "    means= np.mean(sigs, axis=-1)\n",
    "\n",
    "    signatures = np.stack([mins, maxs, means], axis=-1)\n",
    "\n",
    "    return signatures\n",
    "\n",
    "def signature_metric(source_sig:np.ndarray, target_sig:np.ndarray):\n",
    "    # Shape: (n_features, sign_seq_lenght, 3)\n",
    "    min_source = source_sig[0]\n",
    "    max_source = source_sig[1]\n",
    "    mean_source = source_sig[2]\n",
    "\n",
    "    min_target = target_sig[0]\n",
    "    max_target = target_sig[1]\n",
    "    mean_target = target_sig[2]\n",
    "\n",
    "    mean_differences = np.mean(mean_target- mean_source)\n",
    "    area_source = np.mean(max_source- min_source)\n",
    "    area_target = np.mean(max_target- min_target)\n",
    "\n",
    "    met = np.power(mean_differences, 2) + Metric.noise_senssitivity*np.power(area_target- area_source, 2)\n",
    "\n",
    "    return met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_style1 = dset_style1.batch(BS)\n",
    "batched_style2 = dset_style2.batch(BS)\n",
    "\n",
    "style_1_seq, _ = next(iter(batched_style1))\n",
    "style_1_signature = signature_on_batch(style_1_seq, config.met_params.ins, config.met_params.outs, config.met_params.signature_length)\n",
    "\n",
    "style_2_seq, _ = next(iter(batched_style2))\n",
    "style_2_signature = signature_on_batch(style_2_seq, config.met_params.ins, config.met_params.outs, config.met_params.signature_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.RMSprop()\n",
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(0.0005)  \n",
    "\n",
    "generator_metric = tf.keras.metrics.Mean() # Total Generator metric.\n",
    "style_loss_of_generations_metric = tf.keras.metrics.Mean()\n",
    "discriminator_on_fake_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "realness_metric = tf.keras.metrics.Mean() # Discriminator loss...\n",
    "style_classif_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "style1_corr_metric = tf.keras.metrics.Mean()\n",
    "style2_corr_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "sim_loss_metric = tf.keras.metrics.Mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "date_str = datetime.now().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "\n",
    "BASE_DIR = f\"logs/{date_str} - Multi task discriminator\"\n",
    "TRAIN_LOGS_DIR_PATH = f\"{BASE_DIR}/fit\"\n",
    "GENERATION_LOG = f\"{BASE_DIR}/Generations\"\n",
    "\n",
    "TRAIN_SUMMARY_WRITER = tf.summary.create_file_writer(TRAIN_LOGS_DIR_PATH)\n",
    "\n",
    "def plot_to_buff(generations_style1:np.ndarray, generations_style2:np.ndarray, nvertical:int=4):\n",
    "    legend = [f\"feat {j}\" for j in range(generations_style1.shape[-1])]\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    plt.suptitle(\"Generations After GAN Training.\")\n",
    "\n",
    "    for i in range(nvertical):\n",
    "        ax = plt.subplot(nvertical, 2, 2* i+ 1)\n",
    "        ax.set_title(f\"Sequence {i+ 1} Style 1\")\n",
    "\n",
    "        plt.plot(generations_style1[i])\n",
    "        ax.grid(True)\n",
    "        plt.legend(legend)\n",
    "\n",
    "        ax = plt.subplot(nvertical, 2, 2* i+ 2)\n",
    "        ax.set_title(f\"Sequence {i+ 1} Style 2\")\n",
    "\n",
    "        plt.plot(generations_style2[i])\n",
    "        ax.grid(True)\n",
    "        plt.legend(legend)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    plt.close(fig)\n",
    "    return buf\n",
    "\n",
    "\n",
    "def log_losses(epoch, plot_buf):\n",
    "\n",
    "    image = tf.image.decode_png(plot_buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "\n",
    "    with TRAIN_SUMMARY_WRITER.as_default():\n",
    "        tf.summary.scalar(\"0 - Style 1 Correlation Metric\", style1_corr_metric.result(), step=epoch)\n",
    "        tf.summary.scalar(\"0 - Style 2 Correlation Metric\", style2_corr_metric.result(), step=epoch)\n",
    "\n",
    "        tf.summary.scalar(\"1 - Total Generator Loss\", generator_metric.result(), step=epoch)\n",
    "        tf.summary.scalar(\"1 - Discriminator on Generations\", discriminator_on_fake_metric.result(), step=epoch)\n",
    "        tf.summary.scalar(\"1 - Style Loss on Generations\", style_loss_of_generations_metric.result(), step=epoch)\n",
    "\n",
    "        tf.summary.scalar(\"2 - Discriminator Loss\", realness_metric.result(), step=epoch)\n",
    "        tf.summary.scalar(\"3 - Style Classification Loss\", style_classif_metric.result(), step=epoch)\n",
    "\n",
    "        tf.summary.scalar(\"4 - Is Colapsing\", sim_loss_metric.result(), step=epoch)\n",
    "        \n",
    "        tf.summary.image(\"Training Generations\", image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_is_ok(labels):\n",
    "    return labels[labels == 1].shape[0] > 0 and labels[labels == 0].shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(real_sequences, style_labels):\n",
    "    noise= wiener_process(BS, N_SAMPLE_WIENER, FEAT_WIENER)\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        gen_sequences = generator([noise, style_labels])\n",
    "        pred_on_fake, classif_on_fake= discriminator(gen_sequences)\n",
    "        extracted_feat = feature_projector(gen_sequences)\n",
    "\n",
    "        gen_loss= generator_loss(pred_on_fake)\n",
    "        style_on_fake= style_classsification_loss(classif_on_fake, style_labels)\n",
    "\n",
    "        feature_style1 = extracted_feat[style_labels == 0.]\n",
    "        feature_style2 = extracted_feat[style_labels == 1.]\n",
    "\n",
    "        sim_loss_style_1 = similarity_loss(feature_style1)\n",
    "        sim_loss_style_2 = similarity_loss(feature_style2)\n",
    "\n",
    "        sim_loss= (sim_loss_style_1+ sim_loss_style_2)/ 2\n",
    "\n",
    "        final_gen_loss = gen_loss+ style_on_fake + sim_loss\n",
    "\n",
    "    with  tf.GradientTape() as disc_tape:\n",
    "        pred_on_real, classif_on_real= discriminator(real_sequences)\n",
    "        pred_on_fake, classif_on_fake= discriminator(gen_sequences)\n",
    "\n",
    "        dis_loss = discriminator_loss(pred_on_real, pred_on_fake)\n",
    "        style_on_real= style_classsification_loss(classif_on_real, style_labels)\n",
    "\n",
    "    discr_grads= disc_tape.gradient([dis_loss, style_on_real], discriminator.trainable_variables)\n",
    "    gen_grads= gen_tape.gradient(final_gen_loss, generator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discr_grads, discriminator.trainable_variables))\n",
    "\n",
    "    generator_metric(final_gen_loss)\n",
    "    style_loss_of_generations_metric(style_on_fake)\n",
    "    discriminator_on_fake_metric(gen_loss)\n",
    "    \n",
    "\n",
    "    realness_metric(dis_loss)\n",
    "    style_classif_metric(style_on_real)\n",
    "    sim_loss_metric(sim_loss)\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    n_steps = \"?\"\n",
    "    for e in range(EPOCHS):\n",
    "        generator_metric.reset_states()\n",
    "        realness_metric.reset_states()\n",
    "        style_classif_metric.reset_states()\n",
    "        style1_corr_metric.reset_states()\n",
    "        style2_corr_metric.reset_states()\n",
    "        sim_loss_metric.reset_states()\n",
    "\n",
    "        for b, (sequence, style_label) in enumerate(dset):\n",
    "            if style_is_ok(style_label):\n",
    "                train_step(sequence, style_label)\n",
    "                print(f\"\\r EPOCH {e} [{b}/{n_steps}]\\\n",
    " Total Gen Loss: {generator_metric.result():0.4f};\\\n",
    " Style classification on Gen: {style_loss_of_generations_metric.result():0.4f};\\\n",
    " D on Generations: {discriminator_on_fake_metric.result():0.4f};\\\n",
    " Similarity loss: {sim_loss_metric.result():0.4f};\\\n",
    " D Loss: {realness_metric.result():0.4f};\\\n",
    " Style classif loss: {style_classif_metric.result():0.4f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "        if e == 0:\n",
    "            n_steps = b\n",
    "\n",
    "        # Compute our metric.\n",
    "        gen_style1 = generator([seed, tf.zeros(NUM_SEQUENCE_TO_GENERATE, 1)], training=False)\n",
    "        gen_style2 = generator([seed, tf.zeros(NUM_SEQUENCE_TO_GENERATE, 1)+ 1], training=False)\n",
    "\n",
    "        gen_style1_signature= signature_on_batch(gen_style1, config.met_params.ins, config.met_params.outs, config.met_params.signature_length)\n",
    "        gen_style2_signature= signature_on_batch(gen_style2, config.met_params.ins, config.met_params.outs, config.met_params.signature_length)\n",
    "\n",
    "        style1_sig_diff= signature_metric(style_1_signature, gen_style1_signature)\n",
    "        style2_sig_diff= signature_metric(style_2_signature, gen_style2_signature)\n",
    "\n",
    "        style1_corr_metric(style1_sig_diff)\n",
    "        style2_corr_metric(style2_sig_diff)\n",
    "\n",
    "        print(f\" [SIGNATURE DIFFERENCE]: Style 1: {style1_sig_diff:0.4f}; Style 2: {style2_sig_diff:0.4f}\")\n",
    "\n",
    "        buff = plot_to_buff(gen_style1, gen_style2)\n",
    "\n",
    "\n",
    "        log_losses(e, buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sequences = generator([seed, tf.zeros(BS, 1)])\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(generated_sequences[0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sequences = generator([seed, tf.zeros(BS, 1)+ 1])\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(generated_sequences[0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
